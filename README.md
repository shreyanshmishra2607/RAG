# Enhanced Dynamic RAG System

A sophisticated Retrieval-Augmented Generation (RAG) system that intelligently determines when to search the web versus handle queries conversationally, preventing unnecessary web searches for greetings and casual conversation.

## ğŸŒŸ Features

- **Smart Query Classification**: Automatically distinguishes between conversational queries and informational requests
- **Real-time Web Search**: Uses SerpAPI for current information retrieval
- **Vector-based Semantic Search**: ChromaDB with sentence transformers for intelligent content matching
- **Multi-modal Response Generation**: Different response structures based on query type
- **Math Query Handling**: Direct calculation capabilities for mathematical expressions
- **Source Attribution**: Automatic citation of web sources
- **Conversational AI**: Natural dialogue handling without unnecessary web searches

## ğŸ—ï¸ System Architecture

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    USER INPUT PROCESSING                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              CONVERSATIONAL DETECTION                           â”‚
â”‚  â€¢ Pattern matching for greetings, casual chat                 â”‚
â”‚  â€¢ Returns direct response if conversational                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚ (If NOT conversational)
                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                QUERY CLASSIFICATION                             â”‚
â”‚  â€¢ Classify into: real-time, static, code, math, etc.          â”‚
â”‚  â€¢ Determine response type: explanation, comparison, etc.       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  MATH DETECTION                                 â”‚
â”‚  â€¢ Direct calculation for simple math expressions              â”‚
â”‚  â€¢ Uses eval() for basic arithmetic                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚ (If NOT math)
                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   WEB SEARCH                                    â”‚
â”‚  â€¢ SerpAPI (Google Search) integration                         â”‚
â”‚  â€¢ Retrieves top-k results with titles & snippets              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚               TEXT PROCESSING                                   â”‚
â”‚  â€¢ Clean and normalize retrieved text                          â”‚
â”‚  â€¢ Chunk text into manageable pieces (100-150 words)           â”‚
â”‚  â€¢ Maintain source URL associations                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              VECTOR STORAGE                                     â”‚
â”‚  â€¢ Generate embeddings using SentenceTransformer               â”‚
â”‚  â€¢ Store in ChromaDB with metadata                             â”‚
â”‚  â€¢ Clear previous documents to avoid duplicates                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚             SEMANTIC SEARCH                                     â”‚
â”‚  â€¢ Convert user query to embedding                             â”‚
â”‚  â€¢ Find top-k most similar chunks                              â”‚
â”‚  â€¢ Retrieve relevant context + source URLs                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          STRUCTURED ANSWER GENERATION                          â”‚
â”‚  â€¢ Use Ollama LLM with context                                 â”‚
â”‚  â€¢ Apply response-type specific templates                      â”‚
â”‚  â€¢ Include source citations                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 FINAL RESPONSE                                  â”‚
â”‚  â€¢ Formatted answer with sources                               â”‚
â”‚  â€¢ Return to user                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜


## ğŸš€ Quick Start

### Prerequisites

- Python 3.8+
- Ollama server running locally
- SerpAPI account and API key

### Installation

1. **Clone or download the system files**

2. **Install required dependencies:**
```bash
pip install sentence-transformers chromadb serpapi python-dotenv requests
```

3. **Set up Ollama:**
```bash
# Install Ollama (visit https://ollama.ai for instructions)
# Pull the required model
ollama pull llama3
```

4. **Create environment file:**
Create a `.env` file in the project directory:
```env
SERP_API_KEY=your_serpapi_key_here
OLLAMA_HOST=your_ollama_host_url
OLLAMA_MODEL=your_preferred_model
OLLAMA_TIMEOUT=your_timeout_value
```

5. **Run the system:**
```bash
python rag_system.py
```

## ğŸ”§ Configuration

### Environment Variables

| Variable | Description | Default | Required |
|----------|-------------|---------|----------|
| `SERP_API_KEY` | SerpAPI key for web search | None | Yes |
| `OLLAMA_HOST` | Ollama server URL | localhost | No |
| `OLLAMA_MODEL` | AI model name | llama3 | No |
| `OLLAMA_TIMEOUT` | Request timeout in seconds | 30 | No |

### Getting SerpAPI Key

1. Visit [SerpAPI](https://serpapi.com/)
2. Sign up for a free account
3. Get your API key from the dashboard
4. Add it to your `.env` file

## ğŸ’¬ Usage Examples

### Conversational Queries (No Web Search)
```
User: Hi there!
System: Hello! I'm here to help answer your questions. What would you like to know about?

User: How are you?
System: I'm doing well, thank you for asking! I'm ready to help you find information...

User: What can you do?
System: I can help you with many things:
â€¢ Answer questions by searching current web information
â€¢ Explain complex topics with detailed breakdowns
â€¢ Provide step-by-step instructions...
```

### Informational Queries (Web Search + AI Generation)
```
User: What are the latest developments in artificial intelligence?
System: [Searches web, processes results, generates structured response]

User: How do I bake a chocolate cake?
System: [Provides step-by-step instructions based on current web information]

User: Compare iPhone vs Samsung Galaxy
System: [Creates detailed comparison table with pros/cons]
```

### Math Queries (Direct Calculation)
```
User: What is 25 * 47?
System: The answer is: 1175

User: Calculate 15% of 847,293
System: [Performs calculation and provides result]
```

## ğŸ§  Query Classification System

The system automatically classifies queries into different types:

### Query Types
- **Conversational**: Greetings, casual chat, basic AI questions
- **Informational**: Requests for current information requiring web search
- **Mathematical**: Calculations and mathematical expressions
- **Code**: Programming-related queries
- **Real-time**: Current events, weather, news

### Response Types
- **Explanation**: Detailed concept explanations
- **Step-by-step**: Instructions and procedures
- **Comparison**: Side-by-side comparisons
- **Analysis**: Pros/cons and evaluations
- **Factual**: Specific data points and facts
- **Summary**: Topic overviews

## ğŸ” Technical Components

### 1. Text Processing
- **Cleaning**: Normalization and preprocessing
- **Chunking**: Breaking long texts into manageable pieces
- **Embedding**: Converting text to numerical vectors

### 2. Vector Database (ChromaDB)
- **Storage**: Persistent vector storage
- **Search**: Semantic similarity search
- **Metadata**: Source URL tracking

### 3. Web Search (SerpAPI)
- **Real-time**: Current information retrieval
- **Multiple Sources**: Diverse web content
- **URL Tracking**: Source attribution

### 4. AI Generation (Ollama)
- **Local Processing**: Privacy-focused AI
- **Structured Responses**: Template-based generation
- **Customizable**: Multiple model support

## ğŸ“ Project Structure

```
rag_system/
â”œâ”€â”€ rag_system.py          # Main application file
â”œâ”€â”€ .env                   # Environment variables
â”œâ”€â”€ chroma_store/          # Vector database storage
â”œâ”€â”€ README.md              # This file
â””â”€â”€ requirements.txt       # Python dependencies
```

## ğŸ› ï¸ Customization

### Adding New Conversational Patterns
```python
def is_conversational_query(query):
    # Add your patterns to the conversational_patterns list
    conversational_patterns = [
        r'^your_custom_pattern$',
        # ... existing patterns
    ]
```

### Modifying Response Templates
```python
def generate_structured_answer():
    prompt_templates = {
        "your_custom_type": f"""Your custom prompt template...""",
        # ... existing templates
    }
```

### Adjusting Search Parameters
```python
def search_with_serpapi(query, max_results=5):
    search_params = {
        "num": max_results,    # Adjust number of results
        "gl": "us",           # Change geographic location
        "hl": "en"            # Change language
    }
```

## âš¡ Performance Optimization

### Recommended Settings
- **Chunk Size**: 100-150 words for optimal context
- **Vector Search**: Top 3-8 results for best relevance
- **Timeout**: Configure appropriate timeout values
- **Cache Duration**: 5-10 minutes for repeated queries

### Scaling Considerations
- Use batch processing for multiple queries
- Implement query caching for frequently asked questions
- Consider distributed vector storage for large datasets
- Monitor API rate limits

## ğŸ”’ Privacy & Security

- **Local AI Processing**: Ollama runs locally for privacy
- **API Key Security**: Store keys in environment variables
- **Data Persistence**: ChromaDB stores data locally
- **No External Dependencies**: Minimal third-party services

## ğŸ› Troubleshooting

### Common Issues

1. **"Cannot connect to Ollama"**
   - Ensure Ollama is installed and running
   - Check if the model is pulled: `ollama pull [model_name]`
   - Verify OLLAMA_HOST in .env file

2. **"SERP_API_KEY not found"**
   - Check .env file exists and has correct key
   - Verify API key is valid on SerpAPI dashboard

3. **"No matching documents found"**
   - Query might be too specific
   - Try rephrasing with more common terms
   - Check if web search returned results

4. **Slow Response Times**
   - Increase OLLAMA_TIMEOUT in .env
   - Reduce chunk size or top_k parameters
   - Check internet connection for web searches

### Debug Mode
Enable detailed logging by adding print statements or using Python's logging module:

```python
import logging
logging.basicConfig(level=logging.DEBUG)
```

## ğŸ”„ Future Enhancements

### Planned Features
- [ ] Multi-language support
- [ ] Document upload and processing
- [ ] Advanced math computation
- [ ] Image and multimedia handling
- [ ] API endpoint creation
- [ ] Web interface development

### Performance Improvements
- [ ] Query result caching
- [ ] Batch processing capabilities
- [ ] Distributed vector storage
- [ ] Advanced conversation memory

## ğŸ“ License

This project is open source. Please ensure compliance with all third-party service terms of use (SerpAPI, Ollama, etc.).

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Implement your changes
4. Test thoroughly
5. Submit a pull request

## ğŸ“ Support

For issues and questions:
- Check the troubleshooting section
- Review environment configuration
- Ensure all dependencies are installed
- Verify API keys and services are working

## ğŸ™ Acknowledgments

- **Ollama**: Local AI model serving
- **SerpAPI**: Web search capabilities
- **ChromaDB**: Vector database storage
- **Sentence Transformers**: Text embeddings
- **Python Community**: Various supporting libraries

---

**Ready to explore knowledge with intelligent search! ğŸš€**